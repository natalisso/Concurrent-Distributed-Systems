{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natalisso/Concurrent-Distributed-Systems/blob/master/Fine_tuning_T5_SuperGLUE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-w6E5LpyPD6"
      },
      "source": [
        "# Exploratory Nootebook\n",
        "\n",
        "This nootebook aims to build the experimental setup for the upcoming experiments regarding the guided research scope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9MukfmMTSiu",
        "outputId": "846854e4-3f4d-4e7b-8bf5-36f2f755c4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: neptune in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.1.42)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from neptune) (9.4.0)\n",
            "Requirement already satisfied: PyJWT in /usr/lib/python3/dist-packages (from neptune) (2.3.0)\n",
            "Requirement already satisfied: boto3>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.34.60)\n",
            "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (11.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (8.1.7)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from neptune) (0.18.3)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.16.0)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (4.10.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from neptune) (2.0.7)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.7.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.60 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.28.0->neptune) (1.34.60)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.28.0->neptune) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.28.0->neptune) (0.10.0)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (6.1.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (2.8.2)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (3.19.2)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=2.0.8->neptune) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from swagger-spec-validator>=2.7.4->neptune) (4.19.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.10/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune) (1.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.18.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.4)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>0.1.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.1.1)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.13)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.8.19.20240311)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers[torch]\\\n",
        "sentencepiece\\\n",
        "accelerate\\\n",
        "datasets\\\n",
        "evaluate\\\n",
        "python-dotenv\\\n",
        "neptune\\\n",
        "peft\\\n",
        "rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0_iQRLF7Tz0j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import collections\n",
        "import re\n",
        "from datetime import date\n",
        "from typing import Dict, Final, get_args, Literal\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import drive\n",
        "\n",
        "import neptune\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq,\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "from transformers.integrations import NeptuneCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yFJjLKavRej3"
      },
      "outputs": [],
      "source": [
        "GDRIVE_PATH='/content/gdrive/MyDrive/TUM/GR/guided_research_codes'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxXORS7Z3D5i",
        "outputId": "98e5ca18-43fe-4cb3-a86d-d604dd405bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "['.env', '.git', '.gitignore', '.ipynb_checkpoints', '.neptune', 'Checkpoints', 'Fine_tuning_T5_SuperGLUE.ipynb', 'Models', 'Parameters_analysis.ipynb', 'Predictions', '__pycache__', 'config.py', 'logs', 'utils.py']\n"
          ]
        }
      ],
      "source": [
        "# Connecting Google Drive to Colab to have persistent storage across Colab sessions.\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "os.chdir(GDRIVE_PATH)\n",
        "print(sorted(os.listdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUcxRgNaOfnm",
        "outputId": "a0b4942c-3bf5-423f-924c-340610e28bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 13 00:52:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              49W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vVVOqVeHRVHd"
      },
      "outputs": [],
      "source": [
        "from config import SUPER_GLUE_DATASETS_INFOS\n",
        "from utils import (\n",
        "    correct_inputs_targets,\n",
        "    get_model,\n",
        "    setup_configs,\n",
        "    tokenizer_function,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JdrPr6iZwLSt"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "NEPTUNE_API_TOKEN = os.getenv('NEPTUNE_API_TOKEN')\n",
        "GIT_SSH_TOKEN = os.getenv('GIT_SSH_TOKEN')\n",
        "GITHUB_API_TOKEN = os.getenv('GITHUB_API_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-BzQABeQpF71"
      },
      "outputs": [],
      "source": [
        "os.environ[\"NEPTUNE_API_TOKEN\"] = os.getenv(\"NEPTUNE_API_TOKEN\")\n",
        "os.environ[\"NEPTUNE_PROJECT\"] = \"nssoares022/guided-research\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHzBRv8v0Yb3"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "The scope of the research is to benchmark a language model on [SuperGLUE](https://huggingface.co/datasets/super_glue) dataset. All datasets proposed in the SuperGLUE benchmark are available in the HuggingFace dataset hub. More details about them are provided bellow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_p40DfPCFl_"
      },
      "source": [
        "## SuperGLUE\n",
        "The SuperGLUE is a more recent benchmark styled after GLUE with a new set of more difficult language understanding tasks, improved resources, and a new public leaderboard. It consists of 10 NLP tasks. All tasks are classification tasks, except for the ones from the Similarity and Paraphrase tasks set. More details about SuperGLUE benchmark could be found [here](https://super.gluebenchmark.com/tasks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6tr4TO-NeJ5"
      },
      "source": [
        "### Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egRtwwyuNkrE"
      },
      "source": [
        "* COPA - [The Choice of Plausible Alternatives](https://people.ict.usc.edu/~gordon/copa.html) dataset consists of 1000 questions, split equally into development and test sets of 500 questions each. Each question is composed of a premise and two alternatives, where the task is to select the alternative that more plausibly has a causal relation with the premise.\n",
        "  * **Metrics:** Accuracy.\n",
        "\n",
        "* BoolQ - [The Boolean Questions](https://github.com/google-research-datasets/boolean-questions) is a question answering dataset for yes/no questions containing 15942 examples. Each example is a triplet of (question, passage, answer), with the title of the page as optional additional context.\n",
        "   * **Metrics:** Accuracy.\n",
        "\n",
        "* MultiRC - [The Multi-Sentence Reading Comprehension](https://cogcomp.seas.upenn.edu/multirc/) is a dataset of short paragraphs and multi-sentence questions that can be answered from the content of the paragraph.\n",
        "  * **Metrics:** Exact Match (EM) or F1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyJtEB9lDecD"
      },
      "source": [
        "### Common Sense Reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSzhenvgDWRk"
      },
      "source": [
        "* ReCoRD - [The Reading Comprehension with Commonsense Reasoning](https://sheng-z.github.io/ReCoRD-explorer/) consists of queries automatically generated from CNN/Daily Mail news articles. The answer to each query is a text span from a summarizing passage of the corresponding news.\n",
        "   * **Metrics:** F1-score or Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_EbV2saOTPY"
      },
      "source": [
        "### Coreference Resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f5BIgCCOW6j"
      },
      "source": [
        "* WSC - [The Winograd Schema Challenge](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html) consists of pairs of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution.\n",
        "   * **Metrics:** Accuracy.\n",
        "\n",
        "* AXg - [The Winogender Schema Diagnostics](https://github.com/rudinger/winogender-schemas)\tare minimal pairs of sentences that differ only by the gender of one pronoun in the sentence, designed to test for the presence of gender bias in automated coreference resolution systems.\n",
        "   * **Metrics:** Gender Parity or Accuracy\n",
        "\n",
        "* WiC - [The Words in Context](https://pilehvar.github.io/wic/) is a dataset for detecting the context of the words in a context-sensitive representations, framed as as binary classification task. The instances of this dataset have a target word w, either a verb or a noun, and two contexts, c1 and c2. Each of these contexts triggers a specific meaning of w. The task is to identify if the occurrences of w in c1 and c2 correspond to the same meaning or not.\n",
        "   * **Metrics:** Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS3wM0wmDI88"
      },
      "source": [
        "### Inference Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHlDPfYDZ6H"
      },
      "source": [
        "\n",
        "* RTE - [The Recognizing Textual Entailment](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) datasets come from a series of annual textual entailment challenges. The task is to determine whether the second sentence is the entailment of the first one or not.\n",
        "  * **Metrics:** Accuracy.\n",
        "\n",
        "* CB - [The CommitmentBank](https://github.com/mcdm/CommitmentBank) is a corpus of 1,200 naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator (question, modal, negation, antecedent of conditional).\n",
        "  * **Metrics:** Avg. F1-score or Accuracy.\n",
        "\n",
        "* AXb - [The Broadcoverage Diagnostics](https://gluebenchmark.com/diagnostics) is a set of sentence pairs labeled with their entailment relations (entailment, contradiction, or neutral) in both directions.\n",
        "  * **Metrics:** Matthew's Corr."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKqXaeFkXOjT"
      },
      "source": [
        "# Models\n",
        "\n",
        "For the experiments, we are using the flan-T5 model at different sizes, which are all vailable in the HuggingFace hub:\n",
        "\n",
        "*   [flan-t5-base](https://huggingface.co/google/flan-t5-base) - 248M params\n",
        "*   [flan-t5-large](https://huggingface.co/google/flan-t5-large) - 783M params\n",
        "*   [flan-t5-xl](https://huggingface.co/google/flan-t5-xl) - 3B params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYpXOqTADY0Y"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gePpAnUGRm4N"
      },
      "outputs": [],
      "source": [
        "DATASET_NAME: Final[str] = \"super_glue\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d3BB7iTZYBIg"
      },
      "outputs": [],
      "source": [
        "SuperGlueTask = Literal[\"axb\", \"axg\", \"boolq\", \"cb\", \"copa\", \"multirc\", \"record\", \"rte\", \"wic\", \"wsc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CLUrRP7fWwcM"
      },
      "outputs": [],
      "source": [
        "# Parameters to choose backbone model, PEFT method, and benchmark task\n",
        "model_checkpoint: Literal[\"google/flan-t5-xxl\", \"google/flan-t5-base\", \"google/flan-t5-large\"] = \"google/flan-t5-base\"\n",
        "peft_method: Literal[\"full_tuning\", \"ia3\", \"lora\", \"p_tuning\", \"prefix_tuning\"] = \"full_tuning\"\n",
        "task: SuperGlueTask = \"wic\"\n",
        "assert task in get_args(SuperGlueTask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1JT1GDK7Am2",
        "outputId": "522788b2-6814-43d1-8021-d1e24ce23ae7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Checkpoints/wic_full_tuning_base_2024-03-13',\n",
              " 'Models/wic_full_tuning_base_2024-03-13',\n",
              " 'Predictions/wic_full_tuning_base.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "today = date.today()\n",
        "model_type = model_checkpoint.split(\"-\")[-1]\n",
        "experiment_id = f\"{task}_{peft_method}_{model_type}_{today}\"\n",
        "ckpt_dir = f\"Checkpoints/{experiment_id}\"\n",
        "output_dir = f\"Models/{experiment_id}\"\n",
        "predictions_output_file = f\"Predictions/{task}_{peft_method}_{model_type}.txt\"\n",
        "ckpt_dir, output_dir, predictions_output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCv4rckaBkrk",
        "outputId": "b63371a5-4267-4ac3-f1de-779c7520b115"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuperGLUETaskConfigs(task_name='wic', feature_keys=['sentence1', 'sentence2', 'word'], label_key='label', label_names=['False', 'True'], evaluation_metric='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Get the infos for the specific dataset\n",
        "dataset_infos = SUPER_GLUE_DATASETS_INFOS[task]\n",
        "dataset_infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djwebf1QvraP",
        "outputId": "b06dd3ba-d40b-4cf0-8ff4-e56685f1d0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Download and cache the dataset from the HuggingFace hub\n",
        "dataset = load_dataset(DATASET_NAME, dataset_infos.task_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_VLDxPcXBp3"
      },
      "outputs": [],
      "source": [
        "# Get the pre-trained tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_checkpoint, is_split_into_words=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M59EXn-IODKF"
      },
      "outputs": [],
      "source": [
        "setup_configs(DATASET_NAME, task, tokenizer, model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THGcrEka4boY"
      },
      "outputs": [],
      "source": [
        "# Preprocess the raw dataset\n",
        "corrected_dataset = dataset.map(correct_inputs_targets, batched=True, remove_columns=dataset[\"test\"].column_names)\n",
        "tokenized_dataset = corrected_dataset.map(tokenizer_function, batched=True, remove_columns=[\"input\", \"target\"], load_from_cache_file=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plck-7mXWdGl"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJjRvWq2k4Im"
      },
      "outputs": [],
      "source": [
        "model = get_model(model, peft_method)\n",
        "try:\n",
        "  model.print_trainable_parameters()\n",
        "except:\n",
        "  all_params = model.num_parameters()\n",
        "  print(f\"trainable params: {all_params} || all params: {all_params} || trainable%: 100.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr7zTpN8qxYB"
      },
      "outputs": [],
      "source": [
        "def map_text_int(pred):\n",
        "  global task\n",
        "  text_pred = pred.lower()\n",
        "\n",
        "  if (\"false\" in text_pred) or (\"no\" in text_pred) or (\"choice1\" in text_pred) or (\"contradiction\" in text_pred):\n",
        "    int_pred = 0\n",
        "  elif (\"true\" in text_pred) or (\"yes\" in text_pred) or (\"choice2\" in text_pred) or (\"neutral\"in text_pred):\n",
        "    int_pred = 1\n",
        "  elif \"entailment\" in text_pred:\n",
        "    int_pred = 2\n",
        "  else:\n",
        "    int_pred = -1\n",
        "\n",
        "  # Fix RTE labels -> entailment (0) and not_entailment (1)\n",
        "  if task == \"rte\":\n",
        "    if \"no\" in text_pred:\n",
        "      int_pred = 1\n",
        "    elif \"entailment\" in text_pred:\n",
        "      int_pred = 0\n",
        "    else:\n",
        "      int_pred = -1\n",
        "  return int_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKeZ_7r01Kxi"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "def custom_f1_score(predictions, references):\n",
        "  f1 = 0\n",
        "  for prediction, reference in zip(predictions, references):\n",
        "    prediction_tokens = prediction.split()\n",
        "    reference_tokens = reference.split()\n",
        "    common = Counter(prediction_tokens) & Counter(reference_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(reference_tokens)\n",
        "    f1 += (2 * precision * recall) / (precision + recall)\n",
        "  return f1 / len(references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxudVxWRS_Ni"
      },
      "outputs": [],
      "source": [
        "def custom_compute_metrics(pred):\n",
        "    global DATASET_NAME, dataset_infos\n",
        "\n",
        "    logits = pred.predictions[0]\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = pred.label_ids\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    if dataset_infos.task_name != \"record\":\n",
        "      decoded_preds_int = [map_text_int(pred.strip())\n",
        "                        for pred in decoded_preds]\n",
        "      decoded_labels_int = [map_text_int(label.strip())\n",
        "                        for label in decoded_labels]\n",
        "    if dataset_infos.task_name == \"multirc\":\n",
        "      f1_metric = load(\"f1\")\n",
        "      em_metric = load(\"exact_match\")\n",
        "      return {\"f1\": f1_metric.compute(predictions=decoded_preds_int, references=decoded_labels_int, average=\"micro\")[\"f1\"],\n",
        "              \"exact_match\": em_metric.compute(predictions=decoded_preds, references=decoded_labels)[\"exact_match\"]\n",
        "             }\n",
        "    elif dataset_infos.task_name == \"record\":\n",
        "      ems = [1 if pred_text == label_text else 0\n",
        "             for pred_text, label_text in zip(decoded_preds, decoded_labels)]\n",
        "      return {\"f1\": custom_f1_score(predictions=decoded_preds, references=decoded_labels),\n",
        "              \"exact_match\": sum(ems) / len(ems)\n",
        "             }\n",
        "    else:\n",
        "      metric = load(DATASET_NAME, dataset_infos.task_name)\n",
        "    return metric.compute(predictions=decoded_preds_int, references=decoded_labels_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfyMdT85kOoZ"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dsMzLT1Z3Ue"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    ckpt_dir,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=1e-3,\n",
        "    # gradient_accumulation_steps=4,\n",
        "    # eval_accumulation_steps=64,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=8,\n",
        "    # fp16=True,\n",
        "    # fp16_full_eval=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RskXXMlvYEPN"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    callbacks=[NeptuneCallback(api_token=NEPTUNE_API_TOKEN,\n",
        "                               project='nssoares022/guided-research',\n",
        "                               name=f\"{task}_{peft_method}\",\n",
        "                               capture_hardware_metrics=True,\n",
        "                              )\n",
        "              ],\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=custom_compute_metrics,\n",
        ")\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uudi_1glIoOR"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOLj1t6Mbxxl"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQmXXwYsC_X2"
      },
      "outputs": [],
      "source": [
        "# output_sequences = model.generate(\n",
        "#     torch.IntTensor(tokenized_dataset[\"test\"][\"input_ids\"]),\n",
        "#     attention_mask=torch.IntTensor(tokenized_dataset[\"test\"][\"attention_mask\"]),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZm2g2WuUDEv"
      },
      "outputs": [],
      "source": [
        "raw_preds, _, _ = trainer.predict(tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88FNMNndUCQt"
      },
      "outputs": [],
      "source": [
        "y_preds = np.argmax(raw_preds[0], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t87fz0hGbz-"
      },
      "outputs": [],
      "source": [
        "# y_preds = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahPGTXSNkWau"
      },
      "outputs": [],
      "source": [
        "with open(predictions_output_file, \"w+\") as results_file:\n",
        "  results_file.write('idx,label\\n')\n",
        "  for sample, pred in zip(tokenized_dataset[\"test\"], y_preds):\n",
        "    pred_label = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "    idx = sample[\"idx\"]\n",
        "    results_file.write(f\"{idx},{pred_label}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCdwxAzm8LEC"
      },
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnbdteuqgSoj"
      },
      "outputs": [],
      "source": [
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq0Nn24sp4iO"
      },
      "outputs": [],
      "source": [
        "# trainer.push_to_hub()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPsjUT/ihDS3uogrxyzTZtB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}